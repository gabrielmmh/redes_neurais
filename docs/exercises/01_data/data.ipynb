{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Preparação e Análise de Dados para Redes Neurais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "\n",
    "## Objetivo\n",
    "\n",
    "Explorar separabilidade de classes em 2D, projetar dados 5D para 2D com PCA e preparar o dataset **Spaceship Titanic** para redes neurais com ativação `tanh`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Exercício 1 — Dados 2D (4 classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "N = 100\n",
    "params = {\n",
    "    0: {\"mean\": [2, 3],  \"std\": [0.8, 2.5]},\n",
    "    1: {\"mean\": [5, 6],  \"std\": [1.2, 1.9]},\n",
    "    2: {\"mean\": [8, 1],  \"std\": [0.9, 0.9]},\n",
    "    3: {\"mean\": [15, 4], \"std\": [0.5, 2.0]},\n",
    "}\n",
    "\n",
    "Xs, ys = [], []\n",
    "for c, p in params.items():\n",
    "    mean = np.array(p[\"mean\"])\n",
    "    std = np.array(p[\"std\"])\n",
    "    Xc = np.random.randn(N, 2) * std + mean\n",
    "    Xs.append(Xc)\n",
    "    ys.append(np.full(N, c))\n",
    "\n",
    "X = np.vstack(Xs)\n",
    "y = np.hstack(ys)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "for c in params.keys():\n",
    "    plt.scatter(X[y==c,0], X[y==c,1], s=12, label=f\"Classe {c}\", alpha=0.8)\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Exercício 1 — Distribuição 2D (4 classes)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**  \n",
    "As classes formam nuvens gaussianas distintas em *x1*, mas com diferentes dispersões em *x2*.  \n",
    "Uma única fronteira linear não separa as quatro classes; é necessário múltiplas fronteiras ou um modelo não linear.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Superfícies de decisão com MLP\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "clf = MLPClassifier(hidden_layer_sizes=(16,), activation=\"tanh\", max_iter=2000, random_state=42)\n",
    "clf.fit(X, y)\n",
    "\n",
    "xx, yy = np.meshgrid(\n",
    "    np.linspace(X[:,0].min()-1, X[:,0].max()+1, 300),\n",
    "    np.linspace(X[:,1].min()-1, X[:,1].max()+1, 300),\n",
    ")\n",
    "ZZ = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.contourf(xx, yy, ZZ, alpha=0.25, levels=[-0.5,0.5,1.5,2.5,3.5])\n",
    "for c in params.keys():\n",
    "    plt.scatter(X[y==c,0], X[y==c,1], s=10, label=f\"Classe {c}\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.title(\"Exercício 1 — Superfícies de decisão (MLP tanh)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## Exercício 2 — Dados 5D (A/B) + PCA(2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "np.random.seed(7)\n",
    "\n",
    "muA = np.array([0, 0, 0, 0, 0])\n",
    "SigmaA = np.array([\n",
    "    [1.0, 0.8, 0.1, 0.0, 0.0],\n",
    "    [0.8, 1.0, 0.3, 0.0, 0.0],\n",
    "    [0.1, 0.3, 1.0, 0.5, 0.0],\n",
    "    [0.0, 0.0, 0.5, 1.0, 0.2],\n",
    "    [0.0, 0.0, 0.0, 0.2, 1.0]\n",
    "])\n",
    "\n",
    "muB = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\n",
    "SigmaB = np.array([\n",
    "    [1.5, -0.7, 0.2, 0.0, 0.0],\n",
    "    [-0.7, 1.5, 0.4, 0.0, 0.0],\n",
    "    [0.2, 0.4, 1.5, 0.6, 0.0],\n",
    "    [0.0, 0.0, 0.6, 1.5, 0.3],\n",
    "    [0.0, 0.0, 0.0, 0.3, 1.5]\n",
    "])\n",
    "\n",
    "XA = np.random.multivariate_normal(muA, SigmaA, size=500)\n",
    "XB = np.random.multivariate_normal(muB, SigmaB, size=500)\n",
    "X5 = np.vstack([XA, XB])\n",
    "y5 = np.hstack([np.zeros(500), np.ones(500)])\n",
    "\n",
    "pca = PCA(n_components=2, random_state=42)\n",
    "X2 = pca.fit_transform(X5)\n",
    "\n",
    "plt.figure(figsize=(7,5))\n",
    "plt.scatter(X2[y5==0,0], X2[y5==0,1], s=10, label=\"Classe A\")\n",
    "plt.scatter(X2[y5==1,0], X2[y5==1,1], s=10, label=\"Classe B\")\n",
    "plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\n",
    "plt.title(\"Exercício 2 — PCA (5D → 2D)\")\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**  \n",
    "As classes A e B apresentam deslocamento médio, mas as covariâncias geram sobreposição.  \n",
    "Um perceptron simples não resolve bem; redes com não-linearidades modelam melhor essas fronteiras.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "## Exercício 3 — Spaceship Titanic: pré-processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "csv_path = \"data/spaceship_titanic.csv\"\n",
    "\n",
    "if not os.path.exists(csv_path):\n",
    "    print(\"Baixe o dataset e coloque em\", csv_path)\n",
    "else:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    target_col = \"Transported\"\n",
    "    num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n",
    "    cat_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Cabin\"]\n",
    "\n",
    "    df[target_col] = df[target_col].astype(int)\n",
    "\n",
    "    X = df[num_cols + cat_cols]\n",
    "    y = df[target_col]\n",
    "\n",
    "    num_transform = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    cat_transform = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    pre = ColumnTransformer([\n",
    "        (\"num\", num_transform, num_cols),\n",
    "        (\"cat\", cat_transform, cat_cols)\n",
    "    ])\n",
    "\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "    Xt = pre.fit_transform(X_train)\n",
    "    Xv = pre.transform(X_val)\n",
    "\n",
    "    print(\"Shape treino:\", Xt.shape, \" Shape validação:\", Xv.shape)\n",
    "\n",
    "    # Histogramas antes/depois para Age\n",
    "    fig, (ax1, ax2) = plt.subplots(1,2, figsize=(8,3.5))\n",
    "    ax1.hist(df[\"Age\"].dropna(), bins=40)\n",
    "    ax1.set_title(\"Age — original\")\n",
    "    scaled = StandardScaler().fit_transform(df[[\"Age\"]].fillna(df[\"Age\"].median()))\n",
    "    ax2.hist(scaled, bins=40)\n",
    "    ax2.set_title(\"Age — escalado\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "\n",
    "**Discussão:**  \n",
    "- Variáveis numéricas foram padronizadas (média 0, desvio 1) para melhor desempenho com `tanh`.  \n",
    "- Variáveis categóricas receberam imputação de valores ausentes e codificação *one-hot*.  \n",
    "- A estratégia de imputação foi **mediana** para numéricos e **mais frequente** para categóricos.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "## Conclusões\n",
    "\n",
    "Os experimentos mostraram que, em dados sintéticos 2D, fronteiras lineares são insuficientes, sendo necessário o uso de funções de ativação não lineares. Nos dados 5D projetados em 2D, a presença de correlações reforça essa limitação dos modelos lineares. Já no caso do Spaceship Titanic, o pré-processamento adequado — com imputação, codificação e padronização — é essencial para que redes com `tanh` operem de forma estável e eficiente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
