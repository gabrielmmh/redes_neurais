{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "\n",
    "# Entendendo Perceptrons e Suas Limitações"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Exercício 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "### Geração dos dados\n",
    "\n",
    "- Classe 0: média = [1.5, 1.5], covariância = [[0.5, 0], [0, 0.5]]  \n",
    "- Classe 1: média = [5, 5], covariância = [[0.5, 0], [0, 0.5]]\n",
    "\n",
    "Cada classe terá 1000 amostras. Espera-se separabilidade quase linear, dado o distanciamento entre médias e a baixa variância.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "mean0, cov0 = [1.5, 1.5], [[0.5, 0], [0, 0.5]]\n",
    "mean1, cov1 = [5, 5], [[0.5, 0], [0, 0.5]]\n",
    "\n",
    "# gerar amostras\n",
    "n_samples = 1000\n",
    "class0 = np.random.multivariate_normal(mean0, cov0, n_samples)\n",
    "class1 = np.random.multivariate_normal(mean1, cov1, n_samples)\n",
    "\n",
    "# juntar\n",
    "X = np.vstack((class0, class1))\n",
    "y = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # rótulos {-1, +1}\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\")\n",
    "plt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.legend(); plt.title(\"Dados 2D — Classes 0 e 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, lr=0.01, max_epochs=100, shuffle=True, seed=42):\n",
    "        self.lr = lr\n",
    "        self.max_epochs = max_epochs\n",
    "        self.shuffle = shuffle\n",
    "        self.seed = seed\n",
    "        self.w = None\n",
    "        self.b = None\n",
    "        self.history_ = []  # acurácia por época\n",
    "\n",
    "    @staticmethod\n",
    "    def _step(z):\n",
    "        return np.where(z >= 0.0, 1, -1)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self._step(X @ self.w + self.b)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        rng = np.random.default_rng(self.seed)\n",
    "        n, d = X.shape\n",
    "        self.w = np.zeros(d)\n",
    "        self.b = 0.0\n",
    "        self.history_.clear()\n",
    "\n",
    "        for epoch in range(1, self.max_epochs + 1):\n",
    "            idx = np.arange(n)\n",
    "            if self.shuffle:\n",
    "                rng.shuffle(idx)\n",
    "            updates = 0\n",
    "\n",
    "            for i in idx:\n",
    "                xi, yi = X[i], y[i]\n",
    "                y_hat = self._step(self.w @ xi + self.b)\n",
    "                if y_hat != yi:\n",
    "                    self.w += self.lr * yi * xi\n",
    "                    self.b += self.lr * yi\n",
    "                    updates += 1\n",
    "\n",
    "            # acurácia ao fim da época\n",
    "            acc = (self.predict(X) == y).mean()\n",
    "            self.history_.append(acc)\n",
    "\n",
    "            if updates == 0:  # convergiu\n",
    "                break\n",
    "\n",
    "        return self\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)\n",
    "\n",
    "y_pred = per.predict(X)\n",
    "acc = (y_pred == y).mean()\n",
    "\n",
    "print(f\"Pesos (w): {per.w}\")\n",
    "print(f\"Viés (b): {per.b:.4f}\")\n",
    "print(f\"Acurácia final no conjunto completo: {acc:.4f}\")\n",
    "print(f\"Épocas executadas: {len(per.history_)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_decision_boundary_2d(X, y, w, b, title):\n",
    "    x_min, x_max = X[:,0].min()-1, X[:,0].max()+1\n",
    "    xs = np.linspace(x_min, x_max, 400)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6,6))\n",
    "    ax.scatter(X[y==-1,0], X[y==-1,1], s=10, alpha=0.7, label=\"Classe -1\")\n",
    "    ax.scatter(X[y==+1,0], X[y==+1,1], s=10, alpha=0.7, label=\"Classe +1\")\n",
    "\n",
    "    if abs(w[1]) > 1e-12:\n",
    "        ys = -(w[0]/w[1]) * xs - b / w[1]\n",
    "        ax.plot(xs, ys, \"k--\", lw=2, label=\"Fronteira do perceptron\")\n",
    "\n",
    "    # destacar erros\n",
    "    y_hat = np.where(X @ w + b >= 0, 1, -1)\n",
    "    err = (y_hat != y)\n",
    "    if err.any():\n",
    "        ax.scatter(X[err,0], X[err,1], s=30, facecolors='none', edgecolors='r', label=\"Erros\")\n",
    "\n",
    "    ax.set_title(title)\n",
    "    ax.set_xlabel(\"x1\"); ax.set_ylabel(\"x2\"); ax.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron — fronteira e erros (Ex. 1)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\")\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"Acurácia (treino)\")\n",
    "ax.set_title(\"Convergência do Perceptron (Ex. 1)\")\n",
    "\n",
    "# mostrar valores absolutos, sem offset, com 3 casas\n",
    "ax.ticklabel_format(axis=\"y\", useOffset=False)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\"))\n",
    "ax.set_ylim(0.90, 1.001)          # zoom na faixa alta (ajuste se quiser)\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_hist = 1.0 - np.array(per.history_)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\")\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"Erro (1 - acurácia)\")\n",
    "ax.set_title(\"Erro por época (Ex. 1)\")\n",
    "ax.set_ylim(-0.01, 0.1)           # ajuste conforme seu caso\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "No primeiro cenário, as médias distantes e a baixa variância tornam as classes praticamente linearmente separáveis, e o perceptron converge em poucas épocas, atingindo **100% de acurácia**. A fronteira linear separa perfeitamente as duas nuvens, sem erros residuais, em linha com o teorema do perceptron (convergência em número finito de atualizações para dados separáveis).\n",
    "\n",
    "A aparente “subida imediata” para 1.0 vem do fato de que a acurácia é medida **ao fim da época**. Durante a passagem pelos dados, o perceptron analisa um ponto por vez e, quando erra, **empurra levemente a reta** (ajusta $w$ e $b$) para o lado correto. A soma desses pequenos ajustes na **primeira** época já posiciona a reta quase no lugar ideal, fazendo a acurácia ao final ficar perto de **0,9995** (que aparece como **1,000** ao arredondar). Na época seguinte, como a reta já está bem colocada, quase não há novos erros; ao completar uma época **sem correções** (zero updates), considera-se convergência e o gráfico de erro cai a **0** — aprendizado estável e eficiente."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "## Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parâmetros\n",
    "mean0, cov0 = [3, 3], [[1.5, 0], [0, 1.5]]\n",
    "mean1, cov1 = [4, 4], [[1.5, 0], [0, 1.5]]\n",
    "\n",
    "# gerar amostras\n",
    "n_samples = 1000\n",
    "class0 = np.random.multivariate_normal(mean0, cov0, n_samples)\n",
    "class1 = np.random.multivariate_normal(mean1, cov1, n_samples)\n",
    "\n",
    "# juntar\n",
    "X = np.vstack((class0, class1))\n",
    "y = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # rótulos {-1, +1}\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\")\n",
    "plt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\")\n",
    "plt.xlabel(\"x1\"); plt.ylabel(\"x2\")\n",
    "plt.legend(); plt.title(\"Dados 2D — Classes 0 e 1\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)\n",
    "\n",
    "y_pred = per.predict(X)\n",
    "acc = (y_pred == y).mean()\n",
    "\n",
    "print(f\"Pesos (w): {per.w}\")\n",
    "print(f\"Viés (b): {per.b:.4f}\")\n",
    "print(f\"Acurácia final no conjunto completo: {acc:.4f}\")\n",
    "print(f\"Épocas executadas: {len(per.history_)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron — fronteira e erros (Ex. 2)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\")\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"Acurácia (treino)\")\n",
    "ax.set_title(\"Convergência do Perceptron (Ex. 2)\")\n",
    "\n",
    "# mostrar valores absolutos, sem offset, com 3 casas\n",
    "ax.ticklabel_format(axis=\"y\", useOffset=False)\n",
    "ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\"))\n",
    "ax.yaxis.set_major_locator(MaxNLocator(nbins=6))\n",
    "ax.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_hist = 1.0 - np.array(per.history_)\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "ax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\")\n",
    "ax.set_xlabel(\"Época\")\n",
    "ax.set_ylabel(\"Erro (1 - acurácia)\")\n",
    "ax.set_title(\"Erro por época (Ex. 2)\")\n",
    "ax.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "No segundo cenário, as **médias mais próximas** e a **variância maior** geram forte **sobreposição** entre as classes. Nesse regime, **não existe** uma reta que separe perfeitamente todos os pontos; logo, o perceptron **clássico** (que só para quando não há mais erros em uma época) **não converge**. No nosso experimento, ele chegou ao limite de 100 épocas com acurácia em torno de **0,51**, o que reflete a dificuldade intrínseca do problema.\n",
    "\n",
    "Os gráficos deixam isso claro: a **fronteira linear** cruza a região onde as nuvens se misturam e concentra os **erros** ao seu redor; a **acurácia por época** oscila sem tendência a 1,0; e o **erro** não se aproxima de zero. Isso é esperado quando há **não separabilidade linear**: as atualizações do perceptron continuam corrigindo pontos de um lado e criando novos erros do outro, levando a flutuações em vez de estabilização.\n",
    "\n",
    "Comparado ao Exercício 1, este caso evidencia a **limitação do perceptron**: ele funciona muito bem quando os dados são separáveis por uma reta, mas, com **sobreposição**, tende a estagnar. Para melhorar, é preciso **mais expressividade** (p. ex., MLP com não linearidades) ou **engenharia de atributos**/transformações que tornem a separação mais próxima de linear.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
