{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Template de Entrega","text":"Edi\u00e7\u00e3o <p>2025.1</p>"},{"location":"#grupokit-x","title":"Grupo/Kit X","text":"<ol> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> <li>Maria Oliveira</li> <li>Grupo K<ul> <li>Jo\u00e3o da Silva</li> <li>Pedro de Souza</li> </ul> </li> </ol> <p>Instru\u00e7\u00f5es</p> <p>Voc\u00eas devem utilizar este template como um bloco de notas para registrar o que foi feito e o que falta fazer. Voc\u00eas devem adicionar as informa\u00e7\u00f5es necess\u00e1rias. O template deve ser editado e atualizado a cada entrega, registrando assim a data de entrega e o que foi feito at\u00e9 o momento via Git.</p>"},{"location":"#entregas","title":"Entregas","text":"<ul> <li> Roteiro 1 - Data 23/02/2025</li> <li> Roteiro 2</li> <li> Roteiro 3</li> <li> Roteiro 4</li> <li> Projeto</li> </ul>"},{"location":"#diagramas","title":"Diagramas","text":"<p>Use o Mermaid para criar os diagramas de documenta\u00e7\u00e3o.</p> <p>Mermaid Live Editor</p> <pre><code>flowchart TD\n    Deployment:::orange --&gt;|defines| ReplicaSet\n    ReplicaSet --&gt;|manages| pod((Pod))\n    pod:::red --&gt;|runs| Container\n    Deployment --&gt;|scales| pod\n    Deployment --&gt;|updates| pod\n\n    Service:::orange --&gt;|exposes| pod\n\n    subgraph  \n        ConfigMap:::orange\n        Secret:::orange\n    end\n\n    ConfigMap --&gt; Deployment\n    Secret --&gt; Deployment\n    classDef red fill:#f55\n    classDef orange fill:#ffa500</code></pre>"},{"location":"#codigos","title":"C\u00f3digos","text":"De um arquivo remotoAnota\u00e7\u00f5es no c\u00f3digo main.yaml<pre><code>name: ci\non:\n  - push\n  - pull_request\n\n# Environment\nenv:\n  CI: true\n  PYTHON_VERSION: 3.12\n\n# Jobs to run\njobs:\n\n  # Build and deploy documentation site\n  deploy:\n    if: github.event_name != 'pull_request' &amp;&amp; github.ref == 'refs/heads/main'\n    runs-on: ubuntu-latest\n    steps:\n\n      # Checkout source form GitHub\n      - uses: actions/checkout@v4\n\n      # Install Python runtime and dependencies\n      - uses: actions/setup-python@v4\n        with:\n          python-version: ${{ env.PYTHON_VERSION }}\n\n      # pip\n      - run: |\n          pip install -r requirements.txt\n\n      # deploy\n      - run: |\n          mkdocs gh-deploy --force\n</code></pre> compose.yaml<pre><code>name: app\n\n    db:\n        image: postgres:17\n        environment:\n            POSTGRES_DB: ${POSTGRES_DB:-projeto} # (1)!\n            POSTGRES_USER: ${POSTGRES_USER:-projeto}\n            POSTGRES_PASSWORD: ${POSTGRES_PASSWORD:-projeto}\n        ports:\n            - 5432:5432 #(2)!\n</code></pre> <ol> <li> <p>Caso a vari\u00e1vel de ambiente <code>POSTGRES_DB</code> n\u00e3o exista ou seja nula - n\u00e3o seja definida no arquivo <code>.env</code> - o valor padr\u00e3o ser\u00e1 <code>projeto</code>. Vide documenta\u00e7\u00e3o.</p> </li> <li> <p>Aqui \u00e9 feito um t\u00fanel da porta 5432 do container do banco de dados para a porta 5432 do host (no caso localhost). Em um ambiente de produ\u00e7\u00e3o, essa porta n\u00e3o deve ser exposta, pois ningu\u00e9m de fora do compose deveria acessar o banco de dados diretamente.</p> </li> </ol>"},{"location":"#exemplo-de-video","title":"Exemplo de v\u00eddeo","text":"<p>Lorem ipsum dolor sit amet</p>"},{"location":"#referencias","title":"Refer\u00eancias","text":"<p>Material for MkDocs</p>"},{"location":"exercises/01_data/data/","title":"Prepara\u00e7\u00e3o e An\u00e1lise de Dados para Redes Neurais","text":"In\u00a0[7]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n\nN = 100\nparams = {\n    0: {\"mean\": [2, 3],  \"std\": [0.8, 2.5]},\n    1: {\"mean\": [5, 6],  \"std\": [1.2, 1.9]},\n    2: {\"mean\": [8, 1],  \"std\": [0.9, 0.9]},\n    3: {\"mean\": [15, 4], \"std\": [0.5, 2.0]},\n}\n\nXs, ys = [], []\nfor c, p in params.items():\n    mean = np.array(p[\"mean\"])\n    std = np.array(p[\"std\"])\n    Xc = np.random.randn(N, 2) * std + mean\n    Xs.append(Xc)\n    ys.append(np.full(N, c))\n\nX = np.vstack(Xs)\ny = np.hstack(ys)\n\nplt.figure(figsize=(7,5))\nfor c in params.keys():\n    plt.scatter(X[y==c,0], X[y==c,1], s=12, label=f\"Classe {c}\", alpha=0.8)\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.title(\"Exerc\u00edcio 1 \u2014 Distribui\u00e7\u00e3o 2D (4 classes)\")\nplt.legend()\nplt.show()\n</pre>  import numpy as np import matplotlib.pyplot as plt  np.random.seed(42)  N = 100 params = {     0: {\"mean\": [2, 3],  \"std\": [0.8, 2.5]},     1: {\"mean\": [5, 6],  \"std\": [1.2, 1.9]},     2: {\"mean\": [8, 1],  \"std\": [0.9, 0.9]},     3: {\"mean\": [15, 4], \"std\": [0.5, 2.0]}, }  Xs, ys = [], [] for c, p in params.items():     mean = np.array(p[\"mean\"])     std = np.array(p[\"std\"])     Xc = np.random.randn(N, 2) * std + mean     Xs.append(Xc)     ys.append(np.full(N, c))  X = np.vstack(Xs) y = np.hstack(ys)  plt.figure(figsize=(7,5)) for c in params.keys():     plt.scatter(X[y==c,0], X[y==c,1], s=12, label=f\"Classe {c}\", alpha=0.8) plt.xlabel(\"x1\"); plt.ylabel(\"x2\") plt.title(\"Exerc\u00edcio 1 \u2014 Distribui\u00e7\u00e3o 2D (4 classes)\") plt.legend() plt.show()  <p>As quatro classes se distribuem em regi\u00f5es distintas do plano, cada uma concentrada em torno de um centro espec\u00edfico. Embora o eixo x1 contribua fortemente para a separa\u00e7\u00e3o, a variabilidade em x2 cria dispers\u00f5es diferentes entre os grupos. Esse cen\u00e1rio exige a combina\u00e7\u00e3o de m\u00faltiplas fronteiras de decis\u00e3o ou o uso de modelos n\u00e3o lineares para capturar de forma adequada a estrutura dos dados.</p> In\u00a0[8]: Copied! <pre># Superf\u00edcies de decis\u00e3o com MLP\nfrom sklearn.neural_network import MLPClassifier\n\nclf = MLPClassifier(hidden_layer_sizes=(16,), activation=\"tanh\", max_iter=2000, random_state=42)\nclf.fit(X, y)\n\nxx, yy = np.meshgrid(\n    np.linspace(X[:,0].min()-1, X[:,0].max()+1, 300),\n    np.linspace(X[:,1].min()-1, X[:,1].max()+1, 300),\n)\nZZ = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)\n\nplt.figure(figsize=(7,5))\nplt.contourf(xx, yy, ZZ, alpha=0.25, levels=[-0.5,0.5,1.5,2.5,3.5])\nfor c in params.keys():\n    plt.scatter(X[y==c,0], X[y==c,1], s=10, label=f\"Classe {c}\")\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.title(\"Exerc\u00edcio 1 \u2014 Superf\u00edcies de decis\u00e3o (MLP tanh)\")\nplt.legend()\nplt.show()\n</pre>  # Superf\u00edcies de decis\u00e3o com MLP from sklearn.neural_network import MLPClassifier  clf = MLPClassifier(hidden_layer_sizes=(16,), activation=\"tanh\", max_iter=2000, random_state=42) clf.fit(X, y)  xx, yy = np.meshgrid(     np.linspace(X[:,0].min()-1, X[:,0].max()+1, 300),     np.linspace(X[:,1].min()-1, X[:,1].max()+1, 300), ) ZZ = clf.predict(np.c_[xx.ravel(), yy.ravel()]).reshape(xx.shape)  plt.figure(figsize=(7,5)) plt.contourf(xx, yy, ZZ, alpha=0.25, levels=[-0.5,0.5,1.5,2.5,3.5]) for c in params.keys():     plt.scatter(X[y==c,0], X[y==c,1], s=10, label=f\"Classe {c}\") plt.xlabel(\"x1\"); plt.ylabel(\"x2\") plt.title(\"Exerc\u00edcio 1 \u2014 Superf\u00edcies de decis\u00e3o (MLP tanh)\") plt.legend() plt.show()  In\u00a0[9]: Copied! <pre>from sklearn.decomposition import PCA\n\nnp.random.seed(7)\n\nmuA = np.array([0, 0, 0, 0, 0])\nSigmaA = np.array([\n    [1.0, 0.8, 0.1, 0.0, 0.0],\n    [0.8, 1.0, 0.3, 0.0, 0.0],\n    [0.1, 0.3, 1.0, 0.5, 0.0],\n    [0.0, 0.0, 0.5, 1.0, 0.2],\n    [0.0, 0.0, 0.0, 0.2, 1.0]\n])\n\nmuB = np.array([1.5, 1.5, 1.5, 1.5, 1.5])\nSigmaB = np.array([\n    [1.5, -0.7, 0.2, 0.0, 0.0],\n    [-0.7, 1.5, 0.4, 0.0, 0.0],\n    [0.2, 0.4, 1.5, 0.6, 0.0],\n    [0.0, 0.0, 0.6, 1.5, 0.3],\n    [0.0, 0.0, 0.0, 0.3, 1.5]\n])\n\nXA = np.random.multivariate_normal(muA, SigmaA, size=500)\nXB = np.random.multivariate_normal(muB, SigmaB, size=500)\nX5 = np.vstack([XA, XB])\ny5 = np.hstack([np.zeros(500), np.ones(500)])\n\npca = PCA(n_components=2, random_state=42)\nX2 = pca.fit_transform(X5)\n\nplt.figure(figsize=(7,5))\nplt.scatter(X2[y5==0,0], X2[y5==0,1], s=10, label=\"Classe A\")\nplt.scatter(X2[y5==1,0], X2[y5==1,1], s=10, label=\"Classe B\")\nplt.xlabel(\"PC1\"); plt.ylabel(\"PC2\")\nplt.title(\"Exerc\u00edcio 2 \u2014 PCA (5D \u2192 2D)\")\nplt.legend()\nplt.show()\n</pre>  from sklearn.decomposition import PCA  np.random.seed(7)  muA = np.array([0, 0, 0, 0, 0]) SigmaA = np.array([     [1.0, 0.8, 0.1, 0.0, 0.0],     [0.8, 1.0, 0.3, 0.0, 0.0],     [0.1, 0.3, 1.0, 0.5, 0.0],     [0.0, 0.0, 0.5, 1.0, 0.2],     [0.0, 0.0, 0.0, 0.2, 1.0] ])  muB = np.array([1.5, 1.5, 1.5, 1.5, 1.5]) SigmaB = np.array([     [1.5, -0.7, 0.2, 0.0, 0.0],     [-0.7, 1.5, 0.4, 0.0, 0.0],     [0.2, 0.4, 1.5, 0.6, 0.0],     [0.0, 0.0, 0.6, 1.5, 0.3],     [0.0, 0.0, 0.0, 0.3, 1.5] ])  XA = np.random.multivariate_normal(muA, SigmaA, size=500) XB = np.random.multivariate_normal(muB, SigmaB, size=500) X5 = np.vstack([XA, XB]) y5 = np.hstack([np.zeros(500), np.ones(500)])  pca = PCA(n_components=2, random_state=42) X2 = pca.fit_transform(X5)  plt.figure(figsize=(7,5)) plt.scatter(X2[y5==0,0], X2[y5==0,1], s=10, label=\"Classe A\") plt.scatter(X2[y5==1,0], X2[y5==1,1], s=10, label=\"Classe B\") plt.xlabel(\"PC1\"); plt.ylabel(\"PC2\") plt.title(\"Exerc\u00edcio 2 \u2014 PCA (5D \u2192 2D)\") plt.legend() plt.show()  <p>A proje\u00e7\u00e3o via PCA mostra que as classes A e B t\u00eam centros deslocados, mas ainda apresentam forte sobreposi\u00e7\u00e3o devido \u00e0 vari\u00e2ncia dentro de cada grupo. Essa configura\u00e7\u00e3o torna a separa\u00e7\u00e3o linear pouco eficaz, j\u00e1 que n\u00e3o existe um hiperplano simples que separe bem as duas classes. Modelos mais expressivos, que incorporam n\u00e3o-linearidades, s\u00e3o mais adequados para capturar as fronteiras complexas observadas no espa\u00e7o reduzido.</p> <p>O dataset Spaceship Titanic foi proposto em uma competi\u00e7\u00e3o do Kaggle e tem como objetivo prever a vari\u00e1vel Transported, que indica se um passageiro foi levado para outra dimens\u00e3o durante a viagem.</p> <p>Os dados incluem atributos num\u00e9ricos, como <code>Age</code> e os gastos a bordo (<code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>), e atributos categ\u00f3ricos, como <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code> e <code>Cabin</code>. Antes do treinamento de uma rede neural, \u00e9 necess\u00e1rio inspecionar a base para identificar tipos de vari\u00e1veis, valores ausentes e definir as transforma\u00e7\u00f5es adequadas.</p> In\u00a0[10]: Copied! <pre>import os, numpy as np, pandas as pd, matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nplt.rcParams[\"figure.figsize\"] = (8,3.5)\n\ncsv_path = \"data/train.csv\"\nassert os.path.exists(csv_path), f\"Arquivo n\u00e3o encontrado: {csv_path}\"\n\ndf = pd.read_csv(csv_path)\n\ntarget_col = \"Transported\"\nnum_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\ncat_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Cabin\"]\n\n# Colunas de gastos com forte assimetria (usar log1p)\nspend_cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"]\n</pre> import os, numpy as np, pandas as pd, matplotlib.pyplot as plt from sklearn.model_selection import train_test_split from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer from sklearn.compose import ColumnTransformer from sklearn.pipeline import Pipeline from sklearn.impute import SimpleImputer plt.rcParams[\"figure.figsize\"] = (8,3.5)  csv_path = \"data/train.csv\" assert os.path.exists(csv_path), f\"Arquivo n\u00e3o encontrado: {csv_path}\"  df = pd.read_csv(csv_path)  target_col = \"Transported\" num_cols = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"] cat_cols = [\"HomePlanet\", \"CryoSleep\", \"Destination\", \"VIP\", \"Cabin\"]  # Colunas de gastos com forte assimetria (usar log1p) spend_cols = [\"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\"] In\u00a0[11]: Copied! <pre>print(\"Tipos detectados e relat\u00f3rio de valores ausentes:\")\ndisplay(df[num_cols + cat_cols + [target_col]].dtypes)\n\nna_count = df[num_cols + cat_cols + [target_col]].isna().sum().sort_values(ascending=False)\nna_pct = (na_count / len(df)).round(3)\nmissing_report = pd.DataFrame({\"missing\": na_count, \"pct\": na_pct})\ndisplay(missing_report[missing_report[\"missing\"] &gt; 0])\n</pre> print(\"Tipos detectados e relat\u00f3rio de valores ausentes:\") display(df[num_cols + cat_cols + [target_col]].dtypes)  na_count = df[num_cols + cat_cols + [target_col]].isna().sum().sort_values(ascending=False) na_pct = (na_count / len(df)).round(3) missing_report = pd.DataFrame({\"missing\": na_count, \"pct\": na_pct}) display(missing_report[missing_report[\"missing\"] &gt; 0]) <pre>Tipos detectados e relat\u00f3rio de valores ausentes:\n</pre> <pre>Age             float64\nRoomService     float64\nFoodCourt       float64\nShoppingMall    float64\nSpa             float64\nVRDeck          float64\nHomePlanet       object\nCryoSleep        object\nDestination      object\nVIP              object\nCabin            object\nTransported        bool\ndtype: object</pre> missing pct CryoSleep 217 0.025 ShoppingMall 208 0.024 VIP 203 0.023 HomePlanet 201 0.023 Cabin 199 0.023 VRDeck 188 0.022 FoodCourt 183 0.021 Spa 183 0.021 Destination 182 0.021 RoomService 181 0.021 Age 179 0.021 <p>A inspe\u00e7\u00e3o revelou que os atributos de gastos (<code>RoomService</code>, <code>FoodCourt</code>, <code>ShoppingMall</code>, <code>Spa</code>, <code>VRDeck</code>) e <code>Age</code> s\u00e3o num\u00e9ricos, enquanto <code>HomePlanet</code>, <code>CryoSleep</code>, <code>Destination</code>, <code>VIP</code> e <code>Cabin</code> s\u00e3o categ\u00f3ricos.</p> <p>O relat\u00f3rio de valores ausentes mostrou taxas pr\u00f3ximas de 2% em quase todas as colunas. Isso indica a necessidade de imputa\u00e7\u00e3o sistem\u00e1tica: a mediana para atributos num\u00e9ricos, robusta a outliers, e o valor mais frequente para categ\u00f3ricos, preservando consist\u00eancia.</p> <p>Al\u00e9m disso, os atributos num\u00e9ricos n\u00e3o seguem todos a mesma distribui\u00e7\u00e3o: <code>Age</code> tem assimetria moderada, enquanto os gastos apresentam caudas longas e forte concentra\u00e7\u00e3o em zero. Essa diferen\u00e7a motiva estrat\u00e9gias espec\u00edficas de transforma\u00e7\u00e3o, ilustradas a seguir.</p> In\u00a0[12]: Copied! <pre>def plot_before_after(series, transformer, title_after):\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3.5))\n    ax1.hist(series.dropna().values, bins=40)\n    ax1.set_title(f\"{series.name} \u2014 original\")\n    tr = transformer.fit_transform(series.to_frame())\n    ax2.hist(tr.ravel(), bins=40)\n    ax2.set_title(f\"{series.name} \u2014 {title_after}\")\n    plt.tight_layout(); plt.show()\n\nage_pipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"scaler\", StandardScaler())\n])\nplot_before_after(df[\"Age\"], age_pipe, \"padronizada (StandardScaler)\")\n</pre> def plot_before_after(series, transformer, title_after):     fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(8, 3.5))     ax1.hist(series.dropna().values, bins=40)     ax1.set_title(f\"{series.name} \u2014 original\")     tr = transformer.fit_transform(series.to_frame())     ax2.hist(tr.ravel(), bins=40)     ax2.set_title(f\"{series.name} \u2014 {title_after}\")     plt.tight_layout(); plt.show()  age_pipe = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"median\")),     (\"scaler\", StandardScaler()) ]) plot_before_after(df[\"Age\"], age_pipe, \"padronizada (StandardScaler)\")  In\u00a0[13]: Copied! <pre>food_pipe = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"log\", FunctionTransformer(np.log1p, validate=False)),\n    (\"scaler\", StandardScaler())\n])\nplot_before_after(df[\"FoodCourt\"], food_pipe, \"log1p + padronizada\")\n</pre> food_pipe = Pipeline([     (\"imputer\", SimpleImputer(strategy=\"median\")),     (\"log\", FunctionTransformer(np.log1p, validate=False)),     (\"scaler\", StandardScaler()) ]) plot_before_after(df[\"FoodCourt\"], food_pipe, \"log1p + padronizada\")  <p>Os gr\u00e1ficos confirmam o efeito das transforma\u00e7\u00f5es. Em <code>Age</code>, a padroniza\u00e7\u00e3o centralizou a distribui\u00e7\u00e3o em torno de zero e ajustou a escala para desvio padr\u00e3o um, tornando os valores mais adequados para fun\u00e7\u00f5es de ativa\u00e7\u00e3o como <code>tanh</code>.</p> <p>J\u00e1 em <code>FoodCourt</code>, a aplica\u00e7\u00e3o de <code>log1p</code> antes da padroniza\u00e7\u00e3o reduziu o impacto de caudas longas e outliers, resultando em uma distribui\u00e7\u00e3o mais equilibrada. O mesmo racioc\u00ednio pode ser aplicado \u00e0s demais vari\u00e1veis de gastos.</p> <p>Por fim, os atributos categ\u00f3ricos ser\u00e3o tratados com imputa\u00e7\u00e3o do valor mais frequente e convertidos em indicadores bin\u00e1rios via one-hot encoding. O dataset resultante torna-se mais homog\u00eaneo e apropriado para redes neurais, favorecendo a estabilidade do gradiente e o desempenho do modelo.</p>"},{"location":"exercises/01_data/data/#preparacao-e-analise-de-dados-para-redes-neurais","title":"Prepara\u00e7\u00e3o e An\u00e1lise de Dados para Redes Neurais\u00b6","text":""},{"location":"exercises/01_data/data/#objetivo","title":"Objetivo\u00b6","text":"<p>Explorar separabilidade de classes em 2D, projetar dados 5D para 2D com PCA e preparar o dataset Spaceship Titanic para redes neurais com ativa\u00e7\u00e3o <code>tanh</code>.</p>"},{"location":"exercises/01_data/data/#exercicio-1-dados-2d-4-classes","title":"Exerc\u00edcio 1 \u2014 Dados 2D (4 classes)\u00b6","text":""},{"location":"exercises/01_data/data/#exercicio-2-dados-5d-ab-pca2d","title":"Exerc\u00edcio 2 \u2014 Dados 5D (A/B) + PCA(2D)\u00b6","text":""},{"location":"exercises/01_data/data/#exercicio-3-spaceship-titanic-pre-processamento","title":"Exerc\u00edcio 3 \u2014 Spaceship Titanic: pr\u00e9-processamento\u00b6","text":""},{"location":"exercises/01_data/data/#conclusoes","title":"Conclus\u00f5es\u00b6","text":"<p>Os experimentos mostraram que, em dados sint\u00e9ticos 2D, a separa\u00e7\u00e3o linear n\u00e3o \u00e9 suficiente, exigindo fun\u00e7\u00f5es de ativa\u00e7\u00e3o n\u00e3o lineares para capturar fronteiras mais complexas. Na proje\u00e7\u00e3o dos dados 5D em 2D, a sobreposi\u00e7\u00e3o causada por correla\u00e7\u00f5es entre atributos refor\u00e7a essa limita\u00e7\u00e3o e destaca a necessidade de modelos mais expressivos. J\u00e1 no caso do Spaceship Titanic, o pr\u00e9-processamento com imputa\u00e7\u00e3o, codifica\u00e7\u00e3o categ\u00f3rica e padroniza\u00e7\u00e3o num\u00e9rica foi fundamental para tornar o conjunto compat\u00edvel com redes neurais baseadas em <code>tanh</code>, garantindo maior estabilidade no treinamento e melhor capacidade de generaliza\u00e7\u00e3o.</p>"},{"location":"exercises/02_perceptron/perceptron/","title":"Entendendo Perceptrons e Suas Limita\u00e7\u00f5es","text":"In\u00a0[65]: Copied! <pre>import numpy as np\nimport matplotlib.pyplot as plt\n\nnp.random.seed(42)\n</pre> import numpy as np import matplotlib.pyplot as plt  np.random.seed(42) In\u00a0[66]: Copied! <pre># par\u00e2metros\nmean0, cov0 = [1.5, 1.5], [[0.5, 0], [0, 0.5]]\nmean1, cov1 = [5, 5], [[0.5, 0], [0, 0.5]]\n\n# gerar amostras\nn_samples = 1000\nclass0 = np.random.multivariate_normal(mean0, cov0, n_samples)\nclass1 = np.random.multivariate_normal(mean1, cov1, n_samples)\n\n# juntar\nX = np.vstack((class0, class1))\ny = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # r\u00f3tulos {-1, +1}\n\n# plot\nplt.figure(figsize=(6,6))\nplt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\")\nplt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\")\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.legend(); plt.title(\"Dados 2D \u2014 Classes 0 e 1\")\nplt.show()\n</pre> # par\u00e2metros mean0, cov0 = [1.5, 1.5], [[0.5, 0], [0, 0.5]] mean1, cov1 = [5, 5], [[0.5, 0], [0, 0.5]]  # gerar amostras n_samples = 1000 class0 = np.random.multivariate_normal(mean0, cov0, n_samples) class1 = np.random.multivariate_normal(mean1, cov1, n_samples)  # juntar X = np.vstack((class0, class1)) y = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # r\u00f3tulos {-1, +1}  # plot plt.figure(figsize=(6,6)) plt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\") plt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\") plt.xlabel(\"x1\"); plt.ylabel(\"x2\") plt.legend(); plt.title(\"Dados 2D \u2014 Classes 0 e 1\") plt.show() In\u00a0[67]: Copied! <pre>class Perceptron:\n    def __init__(self, lr=0.01, max_epochs=100, shuffle=True, seed=42):\n        self.lr = lr\n        self.max_epochs = max_epochs\n        self.shuffle = shuffle\n        self.seed = seed\n        self.w = None\n        self.b = None\n        self.history_ = []  # acur\u00e1cia por \u00e9poca\n\n    @staticmethod\n    def _step(z):\n        return np.where(z &gt;= 0.0, 1, -1)\n\n    def predict(self, X):\n        return self._step(X @ self.w + self.b)\n\n    def fit(self, X, y):\n        rng = np.random.default_rng(self.seed)\n        n, d = X.shape\n        self.w = np.zeros(d)\n        self.b = 0.0\n        self.history_.clear()\n\n        for epoch in range(1, self.max_epochs + 1):\n            idx = np.arange(n)\n            if self.shuffle:\n                rng.shuffle(idx)\n            updates = 0\n\n            for i in idx:\n                xi, yi = X[i], y[i]\n                y_hat = self._step(self.w @ xi + self.b)\n                if y_hat != yi:\n                    self.w += self.lr * yi * xi\n                    self.b += self.lr * yi\n                    updates += 1\n\n            # acur\u00e1cia ao fim da \u00e9poca\n            acc = (self.predict(X) == y).mean()\n            self.history_.append(acc)\n\n            if updates == 0:  # convergiu\n                break\n\n        return self\n</pre> class Perceptron:     def __init__(self, lr=0.01, max_epochs=100, shuffle=True, seed=42):         self.lr = lr         self.max_epochs = max_epochs         self.shuffle = shuffle         self.seed = seed         self.w = None         self.b = None         self.history_ = []  # acur\u00e1cia por \u00e9poca      @staticmethod     def _step(z):         return np.where(z &gt;= 0.0, 1, -1)      def predict(self, X):         return self._step(X @ self.w + self.b)      def fit(self, X, y):         rng = np.random.default_rng(self.seed)         n, d = X.shape         self.w = np.zeros(d)         self.b = 0.0         self.history_.clear()          for epoch in range(1, self.max_epochs + 1):             idx = np.arange(n)             if self.shuffle:                 rng.shuffle(idx)             updates = 0              for i in idx:                 xi, yi = X[i], y[i]                 y_hat = self._step(self.w @ xi + self.b)                 if y_hat != yi:                     self.w += self.lr * yi * xi                     self.b += self.lr * yi                     updates += 1              # acur\u00e1cia ao fim da \u00e9poca             acc = (self.predict(X) == y).mean()             self.history_.append(acc)              if updates == 0:  # convergiu                 break          return self  In\u00a0[68]: Copied! <pre>per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)\n\ny_pred = per.predict(X)\nacc = (y_pred == y).mean()\n\nprint(f\"Pesos (w): {per.w}\")\nprint(f\"Vi\u00e9s (b): {per.b:.4f}\")\nprint(f\"Acur\u00e1cia final no conjunto completo: {acc:.4f}\")\nprint(f\"\u00c9pocas executadas: {len(per.history_)}\")\n</pre> per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)  y_pred = per.predict(X) acc = (y_pred == y).mean()  print(f\"Pesos (w): {per.w}\") print(f\"Vi\u00e9s (b): {per.b:.4f}\") print(f\"Acur\u00e1cia final no conjunto completo: {acc:.4f}\") print(f\"\u00c9pocas executadas: {len(per.history_)}\")  <pre>Pesos (w): [0.02627968 0.02874301]\nVi\u00e9s (b): -0.1800\nAcur\u00e1cia final no conjunto completo: 1.0000\n\u00c9pocas executadas: 3\n</pre> In\u00a0[69]: Copied! <pre>def plot_decision_boundary_2d(X, y, w, b, title):\n    x_min, x_max = X[:,0].min()-1, X[:,0].max()+1\n    xs = np.linspace(x_min, x_max, 400)\n\n    fig, ax = plt.subplots(figsize=(6,6))\n    ax.scatter(X[y==-1,0], X[y==-1,1], s=10, alpha=0.7, label=\"Classe -1\")\n    ax.scatter(X[y==+1,0], X[y==+1,1], s=10, alpha=0.7, label=\"Classe +1\")\n\n    if abs(w[1]) &gt; 1e-12:\n        ys = -(w[0]/w[1]) * xs - b / w[1]\n        ax.plot(xs, ys, \"k--\", lw=2, label=\"Fronteira do perceptron\")\n\n    # destacar erros\n    y_hat = np.where(X @ w + b &gt;= 0, 1, -1)\n    err = (y_hat != y)\n    if err.any():\n        ax.scatter(X[err,0], X[err,1], s=30, facecolors='none', edgecolors='r', label=\"Erros\")\n\n    ax.set_title(title)\n    ax.set_xlabel(\"x1\"); ax.set_ylabel(\"x2\"); ax.legend()\n    plt.show()\n\nplot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron \u2014 fronteira e erros (Ex. 1)\")\n</pre> def plot_decision_boundary_2d(X, y, w, b, title):     x_min, x_max = X[:,0].min()-1, X[:,0].max()+1     xs = np.linspace(x_min, x_max, 400)      fig, ax = plt.subplots(figsize=(6,6))     ax.scatter(X[y==-1,0], X[y==-1,1], s=10, alpha=0.7, label=\"Classe -1\")     ax.scatter(X[y==+1,0], X[y==+1,1], s=10, alpha=0.7, label=\"Classe +1\")      if abs(w[1]) &gt; 1e-12:         ys = -(w[0]/w[1]) * xs - b / w[1]         ax.plot(xs, ys, \"k--\", lw=2, label=\"Fronteira do perceptron\")      # destacar erros     y_hat = np.where(X @ w + b &gt;= 0, 1, -1)     err = (y_hat != y)     if err.any():         ax.scatter(X[err,0], X[err,1], s=30, facecolors='none', edgecolors='r', label=\"Erros\")      ax.set_title(title)     ax.set_xlabel(\"x1\"); ax.set_ylabel(\"x2\"); ax.legend()     plt.show()  plot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron \u2014 fronteira e erros (Ex. 1)\")  In\u00a0[70]: Copied! <pre>from matplotlib.ticker import FormatStrFormatter, MaxNLocator\n\nfig, ax = plt.subplots()\nax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\")\nax.set_xlabel(\"\u00c9poca\")\nax.set_ylabel(\"Acur\u00e1cia (treino)\")\nax.set_title(\"Converg\u00eancia do Perceptron (Ex. 1)\")\n\n# mostrar valores absolutos, sem offset, com 3 casas\nax.ticklabel_format(axis=\"y\", useOffset=False)\nax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\"))\nax.set_ylim(0.90, 1.001)          # zoom na faixa alta (ajuste se quiser)\nax.yaxis.set_major_locator(MaxNLocator(nbins=6))\nax.grid(True)\nplt.show()\n</pre> from matplotlib.ticker import FormatStrFormatter, MaxNLocator  fig, ax = plt.subplots() ax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\") ax.set_xlabel(\"\u00c9poca\") ax.set_ylabel(\"Acur\u00e1cia (treino)\") ax.set_title(\"Converg\u00eancia do Perceptron (Ex. 1)\")  # mostrar valores absolutos, sem offset, com 3 casas ax.ticklabel_format(axis=\"y\", useOffset=False) ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\")) ax.set_ylim(0.90, 1.001)          # zoom na faixa alta (ajuste se quiser) ax.yaxis.set_major_locator(MaxNLocator(nbins=6)) ax.grid(True) plt.show()  In\u00a0[71]: Copied! <pre>err_hist = 1.0 - np.array(per.history_)\n\nfig, ax = plt.subplots()\nax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\")\nax.set_xlabel(\"\u00c9poca\")\nax.set_ylabel(\"Erro (1 - acur\u00e1cia)\")\nax.set_title(\"Erro por \u00e9poca (Ex. 1)\")\nax.set_ylim(-0.01, 0.1)           # ajuste conforme seu caso\nax.grid(True)\nplt.show()\n</pre> err_hist = 1.0 - np.array(per.history_)  fig, ax = plt.subplots() ax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\") ax.set_xlabel(\"\u00c9poca\") ax.set_ylabel(\"Erro (1 - acur\u00e1cia)\") ax.set_title(\"Erro por \u00e9poca (Ex. 1)\") ax.set_ylim(-0.01, 0.1)           # ajuste conforme seu caso ax.grid(True) plt.show()  <p>No primeiro cen\u00e1rio, as m\u00e9dias distantes e a baixa vari\u00e2ncia tornam as classes praticamente linearmente separ\u00e1veis, e o perceptron converge em poucas \u00e9pocas, atingindo 100% de acur\u00e1cia. A fronteira linear separa perfeitamente as duas nuvens, sem erros residuais, em linha com o teorema do perceptron (converg\u00eancia em n\u00famero finito de atualiza\u00e7\u00f5es para dados separ\u00e1veis).</p> <p>A aparente \u201csubida imediata\u201d para 1.0 vem do fato de que a acur\u00e1cia \u00e9 medida ao fim da \u00e9poca. Durante a passagem pelos dados, o perceptron analisa um ponto por vez e, quando erra, empurra levemente a reta (ajusta $w$ e $b$) para o lado correto. A soma desses pequenos ajustes na primeira \u00e9poca j\u00e1 posiciona a reta quase no lugar ideal, fazendo a acur\u00e1cia ao final ficar perto de 0,9995 (que aparece como 1,000 ao arredondar). Na \u00e9poca seguinte, como a reta j\u00e1 est\u00e1 bem colocada, quase n\u00e3o h\u00e1 novos erros; ao completar uma \u00e9poca sem corre\u00e7\u00f5es (zero updates), considera-se converg\u00eancia e o gr\u00e1fico de erro cai a 0 \u2014 aprendizado est\u00e1vel e eficiente.</p> In\u00a0[72]: Copied! <pre># par\u00e2metros\nmean0, cov0 = [3, 3], [[1.5, 0], [0, 1.5]]\nmean1, cov1 = [4, 4], [[1.5, 0], [0, 1.5]]\n\n# gerar amostras\nn_samples = 1000\nclass0 = np.random.multivariate_normal(mean0, cov0, n_samples)\nclass1 = np.random.multivariate_normal(mean1, cov1, n_samples)\n\n# juntar\nX = np.vstack((class0, class1))\ny = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # r\u00f3tulos {-1, +1}\n\n# plot\nplt.figure(figsize=(6,6))\nplt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\")\nplt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\")\nplt.xlabel(\"x1\"); plt.ylabel(\"x2\")\nplt.legend(); plt.title(\"Dados 2D \u2014 Classes 0 e 1\")\nplt.show()\n</pre> # par\u00e2metros mean0, cov0 = [3, 3], [[1.5, 0], [0, 1.5]] mean1, cov1 = [4, 4], [[1.5, 0], [0, 1.5]]  # gerar amostras n_samples = 1000 class0 = np.random.multivariate_normal(mean0, cov0, n_samples) class1 = np.random.multivariate_normal(mean1, cov1, n_samples)  # juntar X = np.vstack((class0, class1)) y = np.hstack((-1*np.ones(n_samples), +1*np.ones(n_samples)))  # r\u00f3tulos {-1, +1}  # plot plt.figure(figsize=(6,6)) plt.scatter(class0[:,0], class0[:,1], alpha=0.6, label=\"Classe 0\") plt.scatter(class1[:,0], class1[:,1], alpha=0.6, label=\"Classe 1\") plt.xlabel(\"x1\"); plt.ylabel(\"x2\") plt.legend(); plt.title(\"Dados 2D \u2014 Classes 0 e 1\") plt.show() In\u00a0[73]: Copied! <pre>per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)\n\ny_pred = per.predict(X)\nacc = (y_pred == y).mean()\n\nprint(f\"Pesos (w): {per.w}\")\nprint(f\"Vi\u00e9s (b): {per.b:.4f}\")\nprint(f\"Acur\u00e1cia final no conjunto completo: {acc:.4f}\")\nprint(f\"\u00c9pocas executadas: {len(per.history_)}\")\n</pre> per = Perceptron(lr=0.01, max_epochs=100, shuffle=True, seed=42).fit(X, y)  y_pred = per.predict(X) acc = (y_pred == y).mean()  print(f\"Pesos (w): {per.w}\") print(f\"Vi\u00e9s (b): {per.b:.4f}\") print(f\"Acur\u00e1cia final no conjunto completo: {acc:.4f}\") print(f\"\u00c9pocas executadas: {len(per.history_)}\") <pre>Pesos (w): [0.06092489 0.01368968]\nVi\u00e9s (b): -0.4600\nAcur\u00e1cia final no conjunto completo: 0.5120\n\u00c9pocas executadas: 100\n</pre> In\u00a0[74]: Copied! <pre>plot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron \u2014 fronteira e erros (Ex. 2)\")\n</pre> plot_decision_boundary_2d(X, y, per.w, per.b, \"Perceptron \u2014 fronteira e erros (Ex. 2)\") In\u00a0[78]: Copied! <pre>fig, ax = plt.subplots()\nax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\")\nax.set_xlabel(\"\u00c9poca\")\nax.set_ylabel(\"Acur\u00e1cia (treino)\")\nax.set_title(\"Converg\u00eancia do Perceptron (Ex. 2)\")\n\n# mostrar valores absolutos, sem offset, com 3 casas\nax.ticklabel_format(axis=\"y\", useOffset=False)\nax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\"))\nax.yaxis.set_major_locator(MaxNLocator(nbins=6))\nax.grid(True)\nplt.show()\n</pre> fig, ax = plt.subplots() ax.plot(np.arange(1, len(per.history_)+1), per.history_, marker=\"o\") ax.set_xlabel(\"\u00c9poca\") ax.set_ylabel(\"Acur\u00e1cia (treino)\") ax.set_title(\"Converg\u00eancia do Perceptron (Ex. 2)\")  # mostrar valores absolutos, sem offset, com 3 casas ax.ticklabel_format(axis=\"y\", useOffset=False) ax.yaxis.set_major_formatter(FormatStrFormatter(\"%.3f\")) ax.yaxis.set_major_locator(MaxNLocator(nbins=6)) ax.grid(True) plt.show() In\u00a0[79]: Copied! <pre>err_hist = 1.0 - np.array(per.history_)\n\nfig, ax = plt.subplots()\nax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\")\nax.set_xlabel(\"\u00c9poca\")\nax.set_ylabel(\"Erro (1 - acur\u00e1cia)\")\nax.set_title(\"Erro por \u00e9poca (Ex. 2)\")\nax.grid(True)\nplt.show()\n</pre> err_hist = 1.0 - np.array(per.history_)  fig, ax = plt.subplots() ax.plot(np.arange(1, len(err_hist)+1), err_hist, marker=\"o\") ax.set_xlabel(\"\u00c9poca\") ax.set_ylabel(\"Erro (1 - acur\u00e1cia)\") ax.set_title(\"Erro por \u00e9poca (Ex. 2)\") ax.grid(True) plt.show()  <p>No segundo cen\u00e1rio, as m\u00e9dias mais pr\u00f3ximas e a vari\u00e2ncia maior geram forte sobreposi\u00e7\u00e3o entre as classes. Nesse regime, n\u00e3o existe uma reta que separe perfeitamente todos os pontos; logo, o perceptron cl\u00e1ssico (que s\u00f3 para quando n\u00e3o h\u00e1 mais erros em uma \u00e9poca) n\u00e3o converge. No nosso experimento, ele chegou ao limite de 100 \u00e9pocas com acur\u00e1cia em torno de 0,51, o que reflete a dificuldade intr\u00ednseca do problema.</p> <p>Os gr\u00e1ficos deixam isso claro: a fronteira linear cruza a regi\u00e3o onde as nuvens se misturam e concentra os erros ao seu redor; a acur\u00e1cia por \u00e9poca oscila sem tend\u00eancia a 1,0; e o erro n\u00e3o se aproxima de zero. Isso \u00e9 esperado quando h\u00e1 n\u00e3o separabilidade linear: as atualiza\u00e7\u00f5es do perceptron continuam corrigindo pontos de um lado e criando novos erros do outro, levando a flutua\u00e7\u00f5es em vez de estabiliza\u00e7\u00e3o.</p> <p>Comparado ao Exerc\u00edcio 1, este caso evidencia a limita\u00e7\u00e3o do perceptron: ele funciona muito bem quando os dados s\u00e3o separ\u00e1veis por uma reta, mas, com sobreposi\u00e7\u00e3o, tende a estagnar. Para melhorar, \u00e9 preciso mais expressividade (p. ex., MLP com n\u00e3o linearidades) ou engenharia de atributos/transforma\u00e7\u00f5es que tornem a separa\u00e7\u00e3o mais pr\u00f3xima de linear.</p>"},{"location":"exercises/02_perceptron/perceptron/#entendendo-perceptrons-e-suas-limitacoes","title":"Entendendo Perceptrons e Suas Limita\u00e7\u00f5es\u00b6","text":""},{"location":"exercises/02_perceptron/perceptron/#exercicio-1","title":"Exerc\u00edcio 1\u00b6","text":""},{"location":"exercises/02_perceptron/perceptron/#geracao-dos-dados","title":"Gera\u00e7\u00e3o dos dados\u00b6","text":"<ul> <li>Classe 0: m\u00e9dia = [1.5, 1.5], covari\u00e2ncia = [[0.5, 0], [0, 0.5]]</li> <li>Classe 1: m\u00e9dia = [5, 5], covari\u00e2ncia = [[0.5, 0], [0, 0.5]]</li> </ul> <p>Cada classe ter\u00e1 1000 amostras. Espera-se separabilidade quase linear, dado o distanciamento entre m\u00e9dias e a baixa vari\u00e2ncia.</p>"},{"location":"exercises/02_perceptron/perceptron/#exercicio-2","title":"Exerc\u00edcio 2\u00b6","text":""},{"location":"template/projeto/main/","title":"Projeto","text":"<p>Aqui vai toda a documenta\u00e7\u00e3o do projeto, incluindo o que j\u00e1 foi feito e o que falta fazer.</p>"},{"location":"template/roteiro1/main/","title":"Roteiro 1","text":""},{"location":"template/roteiro1/main/#objetivo","title":"Objetivo","text":"<p>Aqui vai o objetivo macro do roteiro. Por que estamos fazendo o que estamos fazendo?</p>"},{"location":"template/roteiro1/main/#montagem-do-roteiro","title":"Montagem do Roteiro","text":"<p>Os pontos \"tarefas\" s\u00e3o os passos que devem ser seguidos para a realiza\u00e7\u00e3o do roteiro. Eles devem ser claros e objetivos. Com evid\u00eancias claras de que foram realizados.</p>"},{"location":"template/roteiro1/main/#tarefa-1","title":"Tarefa 1","text":"<p>Instalando o MAAS:</p> sudo snap install maas --channel=3.5/Stable <p></p> <p>Dashboard do MAAS</p> <p>Conforme ilustrado acima, a tela inicial do MAAS apresenta um dashboard com informa\u00e7\u00f5es sobre o estado atual dos servidores gerenciados. O dashboard \u00e9 composto por diversos pain\u00e9is, cada um exibindo informa\u00e7\u00f5es sobre um aspecto espec\u00edfico do ambiente gerenciado. Os pain\u00e9is podem ser configurados e personalizados de acordo com as necessidades do usu\u00e1rio.</p>"},{"location":"template/roteiro1/main/#tarefa-2","title":"Tarefa 2","text":""},{"location":"template/roteiro1/main/#app","title":"App","text":""},{"location":"template/roteiro1/main/#tarefa-1_1","title":"Tarefa 1","text":""},{"location":"template/roteiro1/main/#tarefa-2_1","title":"Tarefa 2","text":"<p>Exemplo de diagrama</p> <pre><code>architecture-beta\n    group api(cloud)[API]\n\n    service db(database)[Database] in api\n    service disk1(disk)[Storage] in api\n    service disk2(disk)[Storage] in api\n    service server(server)[Server] in api\n\n    db:L -- R:server\n    disk1:T -- B:server\n    disk2:T -- B:db</code></pre> <p>Mermaid</p>"},{"location":"template/roteiro1/main/#questionario-projeto-ou-plano","title":"Question\u00e1rio, Projeto ou Plano","text":"<p>Esse se\u00e7\u00e3o deve ser preenchida apenas se houver demanda do roteiro.</p>"},{"location":"template/roteiro1/main/#discussoes","title":"Discuss\u00f5es","text":"<p>Quais as dificuldades encontradas? O que foi mais f\u00e1cil? O que foi mais dif\u00edcil?</p>"},{"location":"template/roteiro1/main/#conclusao","title":"Conclus\u00e3o","text":"<p>O que foi poss\u00edvel concluir com a realiza\u00e7\u00e3o do roteiro?</p>"},{"location":"template/roteiro2/main/","title":"Roteiro 2","text":""},{"location":"template/roteiro2/main/#diagrama-de-classes-do-banco","title":"Diagrama de Classes do Banco","text":"<pre><code>classDiagram\n    class Conta {\n        - String id\n        # double saldo\n        - Cliente cliente\n        + sacar(double valor)\n        + depositar(double valor)\n    }\n    class Cliente {\n        - String id\n        - String nome\n        - List&lt;Conta&gt; contas\n    }\n    class PessoaFisica {\n        - String cpf\n    }\n    class PessoaJuridica {\n        - String cnpj\n    }\n    class ContaCorrente {\n        - double limite\n        + sacar(double valor)\n    }\n    class ContaPoupanca {\n        + sacar(double valor)\n    }\n    Conta *-- Cliente\n    Conta &lt;|-- ContaCorrente\n    Conta &lt;|-- ContaPoupanca\n    Cliente &lt;|-- PessoaFisica\n    Cliente &lt;|-- PessoaJuridica</code></pre>"},{"location":"template/roteiro2/main/#diagrama-de-sequencia-de-autorizacao","title":"Diagrama de Seq\u00fc\u00eancia de Autoriza\u00e7\u00e3o","text":"<pre><code>sequenceDiagram\n  autonumber\n  actor User\n  User-&gt;&gt;Auth Service: request with token\n  Auth Service-&gt;&gt;Auth Service: decodes the token and extracts claims\n  Auth Service-&gt;&gt;Auth Service: verifies permissions\n  critical allowed\n    Auth Service-&gt;&gt;Secured Resource: authorizes the request\n    Secured Resource-&gt;&gt;User: returns the response\n  option denied\n    Auth Service--&gt;&gt;User: unauthorized message\n  end  </code></pre>"},{"location":"template/roteiro3/main/","title":"Roteiro 3","text":"<p>Running the code below in Browser (Woooooowwwwww!!!!!!). <sup>1</sup></p> <p> Editor (session: default) Run <pre>import ssl\nimport pandas as pd\n\ndf = pd.DataFrame()\ndf['AAPL'] = pd.Series([1, 2, 3])\ndf['MSFT'] = pd.Series([4, 5, 6])\ndf['GOOGL'] = pd.Series([7, 8, 9])\n\nprint(df)\n</pre> Output Clear <pre></pre> </p> <ol> <li> <p>Pyodide \u21a9</p> </li> </ol>"},{"location":"template/roteiro4/limit.def/","title":"Limit.def","text":"In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nfrom io import StringIO\n</pre> import matplotlib.pyplot as plt import numpy as np from io import StringIO In\u00a0[\u00a0]: Copied! <pre>eq = lambda x: np.exp(x)\n</pre> eq = lambda x: np.exp(x) In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(-.2, 2.1)\n</pre> x = np.linspace(-.2, 2.1) In\u00a0[\u00a0]: Copied! <pre>plt.rcParams[\"figure.figsize\"] = (15, 5)\n</pre> plt.rcParams[\"figure.figsize\"] = (15, 5) In\u00a0[\u00a0]: Copied! <pre>xa = 1.5\nya = 7\nk = 0.3\nka = xa - k\nak = xa + k\n</pre> xa = 1.5 ya = 7 k = 0.3 ka = xa - k ak = xa + k In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 3)\nfor i in range(3):\n  ax[i].axhline(0, color='gray') # x = 0\n  ax[i].axvline(0, color='gray') # y = 0\n  ax[i].spines['top'].set_visible(False)\n  ax[i].spines['right'].set_visible(False)\n  ax[i].spines['bottom'].set_visible(False)\n  ax[i].spines['left'].set_visible(False)\n  ax[i].plot(x, eq(x), '-r', lw=4)\n  ax[i].set_xlim(min(x), max(x))\n  ax[i].set_xticks([])\n  ax[i].set_yticks([])\n  ax[i].plot([ka, ka], [0, eq(ka)], 'g:')\n  ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')\n  ax[i].plot([ak, ak], [0, eq(ak)], 'g:')\n  ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')\n  ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)\n  ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n  ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> fig, ax = plt.subplots(1, 3) for i in range(3):   ax[i].axhline(0, color='gray') # x = 0   ax[i].axvline(0, color='gray') # y = 0   ax[i].spines['top'].set_visible(False)   ax[i].spines['right'].set_visible(False)   ax[i].spines['bottom'].set_visible(False)   ax[i].spines['left'].set_visible(False)   ax[i].plot(x, eq(x), '-r', lw=4)   ax[i].set_xlim(min(x), max(x))   ax[i].set_xticks([])   ax[i].set_yticks([])   ax[i].plot([ka, ka], [0, eq(ka)], 'g:')   ax[i].plot([0, ka], [eq(ka), eq(ka)], 'g:')   ax[i].plot([ak, ak], [0, eq(ak)], 'g:')   ax[i].plot([0, ak], [eq(ak), eq(ak)], 'g:')   ax[i].text(xa, -0.5, 'a', horizontalalignment='center', fontsize=15)   ax[i].text(ka, -0.5, '$a-\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(ak, -0.5, '$a+\\delta$', horizontalalignment='center', fontsize=15)   ax[i].text(0, eq(ka), '$L-\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15)   ax[i].text(0, eq(ak), '$L+\\epsilon$', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>ax[0].plot([xa, xa], [0, eq(xa)], 'b:')\nax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:')\nax[0].plot(xa, eq(xa), 'ro', ms=15)\nax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[1].plot([xa, xa], [0, eq(xa)], 'b:')\nax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white')\nax[2].plot([xa, xa], [0, ya], 'b:')\nax[2].plot([0, xa], [ya, ya], 'b:')\nax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:')\nax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white')\nax[2].plot(xa, ya, 'ro', ms=15)\nax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15)\nax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15)\n</pre> ax[0].plot([xa, xa], [0, eq(xa)], 'b:') ax[0].plot([0, xa], [eq(xa), eq(xa)], 'b:') ax[0].plot(xa, eq(xa), 'ro', ms=15) ax[0].text(0, eq(xa), 'L=f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[1].plot([xa, xa], [0, eq(xa)], 'b:') ax[1].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[1].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[1].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='white', color='white') ax[2].plot([xa, xa], [0, ya], 'b:') ax[2].plot([0, xa], [ya, ya], 'b:') ax[2].plot([0, xa], [eq(xa), eq(xa)], 'm:') ax[2].plot(xa, eq(xa), marker='o', ms=15, mec='red', color='white') ax[2].plot(xa, ya, 'ro', ms=15) ax[2].text(0, ya, 'f(a)', horizontalalignment='right', verticalalignment='center', fontsize=15) ax[2].text(0, eq(xa), 'L', horizontalalignment='right', verticalalignment='center', fontsize=15) In\u00a0[\u00a0]: Copied! <pre>fig.tight_layout()\n</pre> fig.tight_layout() In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\", transparent=True)\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\", transparent=True) print(buffer.getvalue())"},{"location":"template/roteiro4/main/","title":"Roteiro 4","text":"<p>Se chegou aqui, \u00e9 porque voc\u00ea est\u00e1 interessado em saber mais. Logo, de brinde, como rodar um c\u00f3digo <code>Python</code> aqui.</p> <p></p> <p></p> <p>Markdown-exec \u00e9 uma extens\u00e3o do Markdown que permite executar c\u00f3digo Python diretamente no Markdown. Isso \u00e9 \u00fatil para gerar resultados din\u00e2micos ou executar scripts de forma interativa.</p>"},{"location":"template/roteiro4/smc/","title":"Smc","text":"In\u00a0[\u00a0]: Copied! <pre>from datetime import datetime\nimport matplotlib.pyplot as plt\nimport yfinance as yf\nimport numpy as np\nimport pandas as pd\nfrom io import StringIO\n</pre> from datetime import datetime import matplotlib.pyplot as plt import yfinance as yf import numpy as np import pandas as pd from io import StringIO In\u00a0[\u00a0]: Copied! <pre>num_days = 250\nnum_simulations = 200\norder_poly = 1\n</pre> num_days = 250 num_simulations = 200 order_poly = 1 In\u00a0[\u00a0]: Copied! <pre>ticker = '^BVSP'\n</pre> ticker = '^BVSP' In\u00a0[\u00a0]: Copied! <pre>info = yf.Ticker(ticker)\ndata = info.history(period='2y')\n</pre> info = yf.Ticker(ticker) data = info.history(period='2y') In\u00a0[\u00a0]: Copied! <pre>close = data['Close']\ndaily_return = close.pct_change()\n</pre> close = data['Close'] daily_return = close.pct_change() In\u00a0[\u00a0]: Copied! <pre>x = np.linspace(1, len(close), len(close))\nf = np.poly1d(np.polyfit(x, close, order_poly))\nxs = np.linspace(max(x), max(x) + num_days, num_days)\n</pre> x = np.linspace(1, len(close), len(close)) f = np.poly1d(np.polyfit(x, close, order_poly)) xs = np.linspace(max(x), max(x) + num_days, num_days) In\u00a0[\u00a0]: Copied! <pre>sigma = daily_return.std()\nmu = daily_return.mean()\n</pre> sigma = daily_return.std() mu = daily_return.mean() In\u00a0[\u00a0]: Copied! <pre>simulated_prices = np.zeros((num_days, num_simulations))\n</pre> simulated_prices = np.zeros((num_days, num_simulations)) In\u00a0[\u00a0]: Copied! <pre>for i in range(num_simulations):\n    simulated_prices[0][i] = close[-1]\n    for j in range(1, num_days):\n        daily_return = np.random.normal(mu, sigma)\n        simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return)\n</pre> for i in range(num_simulations):     simulated_prices[0][i] = close[-1]     for j in range(1, num_days):         daily_return = np.random.normal(mu, sigma)         simulated_prices[j][i] = simulated_prices[j-1][i] * (1 + daily_return) In\u00a0[\u00a0]: Copied! <pre>simulated_means = np.mean(simulated_prices, axis=1)\nsimulated_stds = np.std(simulated_prices, axis=1)\n</pre> simulated_means = np.mean(simulated_prices, axis=1) simulated_stds = np.std(simulated_prices, axis=1) In\u00a0[\u00a0]: Copied! <pre>fig, ax = plt.subplots(1, 1, figsize=(12, 8))\nax.plot(\n    x, close,\n    x, f(x), 'r:',\n    xs, simulated_prices,\n    xs, simulated_means,\n    xs, simulated_means + 1*simulated_stds, 'w:',\n    xs, simulated_means - 1*simulated_stds, 'w:',\n    xs, simulated_means + 2*simulated_stds, 'k:',\n    xs, simulated_means - 2*simulated_stds, 'k:',\n    xs, f(xs), 'g',\n)\nax.set_xlim(min(x), max(xs))\n</pre> fig, ax = plt.subplots(1, 1, figsize=(12, 8)) ax.plot(     x, close,     x, f(x), 'r:',     xs, simulated_prices,     xs, simulated_means,     xs, simulated_means + 1*simulated_stds, 'w:',     xs, simulated_means - 1*simulated_stds, 'w:',     xs, simulated_means + 2*simulated_stds, 'k:',     xs, simulated_means - 2*simulated_stds, 'k:',     xs, f(xs), 'g', ) ax.set_xlim(min(x), max(xs)) In\u00a0[\u00a0]: Copied! <pre>buffer = StringIO()\nplt.savefig(buffer, format=\"svg\")\nprint(buffer.getvalue())\n</pre> buffer = StringIO() plt.savefig(buffer, format=\"svg\") print(buffer.getvalue())"},{"location":"template/thisdocumentation/main/","title":"This documentation","text":""},{"location":"template/thisdocumentation/main/#pre-requisitos","title":"Pr\u00e9-requisitos","text":"<p>Antes de come\u00e7ar, certifique-se de que voc\u00ea possui os seguintes pr\u00e9-requisitos instalados em seu sistema:</p> <ul> <li>Git: Para clonar o reposit\u00f3rio.</li> </ul>"},{"location":"template/thisdocumentation/main/#instalando-o-python","title":"Instalando o Python","text":"LinuxmacOSWindows <p>Instale o Python 3.8 ou superior.</p> <pre><code>sudo apt install python3 python3-venv python3-pip\npython3 --version\n</code></pre> <p>Instale o Python 3.8 ou superior.</p> <pre><code>brew install python\npython3 --version\n</code></pre> <p>Instale o Python 3.13 ou superior. Baixe o instalador do site oficial do Python (https://www.python.org/downloads/) e execute-o. Certifique-se de marcar a op\u00e7\u00e3o \"Add Python to PATH\" durante a instala\u00e7\u00e3o.</p> <pre><code>python --version\n</code></pre>"},{"location":"template/thisdocumentation/main/#usage","title":"Usage","text":"<p>Para utilizar o c\u00f3digo deste reposit\u00f3rio, siga as instru\u00e7\u00f5es a seguir:</p> <p>Clone ou fork este reposit\u00f3rio:</p> <pre><code>git clone &lt;URL_DO_REPOSITORIO&gt;\n</code></pre> <p>Crie um ambiente virtual do Python:</p> Linux/macOSWindows <pre><code>python3 -m venv env\n</code></pre> <pre><code>python -m venv env\n</code></pre> <p>Ative o ambiente virtual (voc\u00ea deve fazer isso sempre que for executar algum script deste reposit\u00f3rio):</p> Linux/macOSWindows <pre><code>source ./env/bin/activate\n</code></pre> <pre><code>.\\env\\Scripts\\activate\n</code></pre> <p>Instale as depend\u00eancias com:</p> Linux/macOSWindows <pre><code>python3 -m pip install -r requirements.txt --upgrade\n</code></pre> <pre><code>python -m pip install -r requirements.txt --upgrade\n</code></pre>"},{"location":"template/thisdocumentation/main/#deployment","title":"Deployment","text":"<p>O material utiliza o mkdocs para gerar a documenta\u00e7\u00e3o. Para visualizar a documenta\u00e7\u00e3o, execute o comando:</p> <pre><code>mkdocs serve -o\n</code></pre> <p>Para subir ao GitHub Pages, execute o comando:</p> <pre><code>mkdocs gh-deploy\n</code></pre> <p>Esse reposit\u00f3rio possui um workflow do GitHub Actions que executa o comando <code>mkdocs gh-deploy</code> sempre que houver um push na branch <code>main</code>. Assim, n\u00e3o \u00e9 necess\u00e1rio executar esse comando manualmente. Toda vez que voc\u00ea fizer um push na branch <code>main</code>, a documenta\u00e7\u00e3o ser\u00e1 atualizada automaticamente no GitHub Pages.</p> <p>Aviso 1</p> <p>Para que o github actions funcione corretamente, \u00e9 necess\u00e1rio que o reposit\u00f3rio esteja configurado para que o bot <code>github-actions[bot]</code> tenha permiss\u00e3o de escrita. Voc\u00ea pode verificar isso nas configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Actions\" e depois em \"General\". Certifique-se de que a op\u00e7\u00e3o \"Workflow permissions\" esteja definida como \"Read and write permissions\".</p> <p></p> <p>Aviso 2</p> <p>Depois de publicar, caso n\u00e3o consiga acessar a p\u00e1gina, verifique se o github pages est\u00e1 configurado corretamente. V\u00e1 at\u00e9 as configura\u00e7\u00f5es do reposit\u00f3rio, na se\u00e7\u00e3o \"Pages\" e verifique se a branch <code>gh-pages</code> est\u00e1 selecionada como fonte. Se n\u00e3o estiver, selecione-a e salve as altera\u00e7\u00f5es.</p> <p></p> <p>Pay Attention</p> <p>No arquivo '<code>mkdocs.yml</code>, a se\u00e7\u00e3o <code>site_url</code> deve estar configurada corretamente para o seu reposit\u00f3rio. Por exemplo, se o seu reposit\u00f3rio estiver em <code>https://github.com/usuario/repositorio</code>, a se\u00e7\u00e3o <code>site_url</code> deve ser:</p> <pre><code>site_url: https://usuario.github.io/repositorio\n</code></pre> <p>Tamb\u00e9m, certifique-se de que a se\u00e7\u00e3o <code>repo_url</code> esteja configurada corretamente para o seu reposit\u00f3rio. Por exemplo:</p> <pre><code>repo_url: https://github.com/usuario/repositorio\n</code></pre>"}]}